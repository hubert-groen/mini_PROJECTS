{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/iris.csv')\n",
    "np.random.shuffle(train_df.values)\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "train_x = np.column_stack((train_df.SepalLengthCm.values, train_df.SepalWidthCm.values, train_df.PetalLengthCm.values, train_df.PetalWidthCm.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "\n",
      "After label encoding:\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# LABEL ENCODING\n",
    "\n",
    "print(train_df.Species.unique())\n",
    "\n",
    "species_dict = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
    "train_df['Species'] = train_df.Species.apply(lambda x: species_dict[x])\n",
    "\n",
    "print('\\nAfter label encoding:')\n",
    "print(train_df.Species.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODING - using sklearn\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# label_encoder = preprocessing.LabelEncoder()\n",
    "# train_df['Species']= label_encoder.fit_transform(train_df['Species'])\n",
    "# train_df['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "\tkeras.layers.Dense(64, input_shape=(4,), activation='relu'),\n",
    "    # keras.layers.Dropout(0.2),\t\t\t\t\t\t\t\t\t# % of neurons (of previous layer) that will be dropped\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "\tkeras.layers.Dense(64, activation='relu'),\t\t\t\t\t\t# adding layer, because quadratic example is more complex\n",
    "\tkeras.layers.Dense(3, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adadelta\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hubert/.local/lib/python3.10/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 5ms/step - loss: 1.2889 - accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2852 - accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2819 - accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2785 - accuracy: 0.3333\n",
      "\n",
      "Best Accuracy: 0.3333 at epoch 1\n",
      "\n",
      "Adagrad\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 1s 5ms/step - loss: 1.1368 - accuracy: 0.5133\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0204 - accuracy: 0.6333\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9760 - accuracy: 0.4800\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9453 - accuracy: 0.5733\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.9182 - accuracy: 0.5867\n",
      "\n",
      "Best Accuracy: 0.6333 at epoch 2\n",
      "\n",
      "Adam\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 1s 5ms/step - loss: 0.8566 - accuracy: 0.6800\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7667\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8400\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.9067\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9533\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1541 - accuracy: 0.9667\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.9467\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9467\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9600\n",
      "\n",
      "Best Accuracy: 0.9667 at epoch 6\n",
      "\n",
      "RMSprop\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9267\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1461 - accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9467\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9800\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1412 - accuracy: 0.9400\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.9600\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1408 - accuracy: 0.9467\n",
      "\n",
      "Best Accuracy: 0.9800 at epoch 4\n",
      "\n",
      "SGD\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 1s 5ms/step - loss: 0.4235 - accuracy: 0.8333\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2851 - accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.9067\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9133\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9133\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1698 - accuracy: 0.9467\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.8933\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2604 - accuracy: 0.8933\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1580 - accuracy: 0.9467\n",
      "\n",
      "Best Accuracy: 0.9467 at epoch 7\n",
      "\n",
      "\n",
      "------------\n",
      "Optimizers: {'Adadelta': 0.3333, 'Adagrad': 0.6333, 'Adam': 0.9667, 'RMSprop': 0.98, 'SGD': 0.9467}\n",
      "Best optimizer: RMSprop\n"
     ]
    }
   ],
   "source": [
    "optimizers = {'Adadelta': None, 'Adagrad': None, 'Adam': None, 'RMSprop': None, 'SGD': None}\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=3, restore_best_weights=True)\n",
    "\n",
    "best_optimizer = None\n",
    "best_accuracy = 0\n",
    "best_optimizer_weights = None\n",
    "\n",
    "for i, _ in optimizers.items():\n",
    "\n",
    "    print(f'\\n{i}')\n",
    "    model.compile(optimizer=i, loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    results = model.fit(train_x, train_df.Species.values, batch_size=4, epochs=10, callbacks=[early_stopping])\n",
    "\n",
    "    current_accuracy = max(results.history['accuracy'])\n",
    "    print(f'\\nBest Accuracy: {current_accuracy:.4f} at epoch {results.history[\"accuracy\"].index(current_accuracy) + 1}')\n",
    "    optimizers[i] = round(current_accuracy, 4)\n",
    "\n",
    "    if current_accuracy > best_accuracy:\n",
    "        best_optimizer = i\n",
    "        best_accuracy = current_accuracy\n",
    "        best_optimizer_weights = model.get_weights()\n",
    "\n",
    "    \n",
    "print('\\n\\n------------')\n",
    "print(f'Optimizers: {optimizers}')\n",
    "print(f'Best optimizer: {best_optimizer}')\n",
    "\n",
    "model.set_weights(best_optimizer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1048 - accuracy: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hubert/.local/lib/python3.10/site-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('./data/iris.csv')\n",
    "test_x = np.column_stack((test_df.SepalLengthCm.values, test_df.SepalWidthCm.values, test_df.PetalLengthCm.values, test_df.PetalWidthCm.values))\n",
    "\n",
    "test_df['Species'] = test_df.Species.apply(lambda x: species_dict[x])\n",
    "\n",
    "print(\"EVALUATION\")\n",
    "evaluation = model.evaluate(test_x, test_df.Species.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Ground Truth: 2 (Iris-virginica)\n",
      "Prediction: 2 (Iris-virginica)\n",
      "(Probability distribution: [[0.0082 0.7565 0.9823]])\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, len(test_df))\n",
    "\n",
    "random_sample = test_x[random_index].reshape(1, -1)     # reshaping to (1, 4) as there are 4 features\n",
    "\n",
    "ground_truth = test_df.iloc[random_index]['Species']\n",
    "ground_truth_species = None\n",
    "\n",
    "\n",
    "prediction_probs = model.predict(random_sample)\n",
    "prediction_probs = np.round(prediction_probs, decimals=4)\n",
    "\n",
    "predicted_label = np.argmax(prediction_probs)\n",
    "predicted_label_species = None\n",
    "\n",
    "for key, value in species_dict.items():\n",
    "    if value == ground_truth:\n",
    "        ground_truth_species = key\n",
    "    if value == predicted_label:\n",
    "        predicted_label_species = key\n",
    "    if ground_truth_species != None and predicted_label_species != None:\n",
    "        break\n",
    "\n",
    "# Print the ground truth and prediction\n",
    "print(f\"Ground Truth: {int(ground_truth)} ({ground_truth_species})\")\n",
    "print(f\"Prediction: {predicted_label} ({predicted_label_species})\\n(Probability distribution: {prediction_probs})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
